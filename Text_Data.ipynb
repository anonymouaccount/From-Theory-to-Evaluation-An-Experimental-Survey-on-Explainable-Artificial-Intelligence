{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPwLNXZMoiHmL4xisJmXEHm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anonymouaccount/From-Theory-to-Evaluation-An-Experimental-Survey-on-Explainable-Artificial-Intelligence/blob/main/Text_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text **Data**"
      ],
      "metadata": {
        "id": "udS0stdB5sGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deeplift**"
      ],
      "metadata": {
        "id": "Kz10zfpINAXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deeplift"
      ],
      "metadata": {
        "id": "Vdfp1dLV_Zbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install captum"
      ],
      "metadata": {
        "id": "v4jrZXPCD6xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from captum.attr import DeepLift\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import zipfile\n",
        "import re\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "# Mount Google Drive (if using Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "zip_path = '/content/drive/MyDrive/Reviews.zip'  # Path to the zip file\n",
        "extract_to = '/content/Reviews'  # Directory to extract the zip file\n",
        "data_path = os.path.join(extract_to, 'IMDB Dataset.csv')  # CSV file path\n",
        "\n",
        "# Extract the zip file\n",
        "def unzip_data(zip_path, extract_to):\n",
        "    if not os.path.exists(extract_to):\n",
        "        os.makedirs(extract_to)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Unzip the dataset\n",
        "unzip_data(zip_path, extract_to)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Convert sentiment labels to binary\n",
        "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text to numerical features\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Define a simple neural network for DeepLift explanation\n",
        "class SentimentNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SentimentNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 50)\n",
        "        self.fc2 = nn.Linear(50, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Convert TF-IDF to PyTorch tensors\n",
        "X_test_torch = torch.tensor(X_test_tfidf.toarray(), dtype=torch.float32)\n",
        "y_test_torch = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Initialize and load the model\n",
        "input_dim = X_train_tfidf.shape[1]\n",
        "model = SentimentNN(input_dim)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the neural network\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_test_torch)\n",
        "    loss = criterion(outputs, y_test_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "# DeepLift explanation\n",
        "deep_lift = DeepLift(model)\n",
        "\n",
        "def explain_instance(instance, target_class=1):\n",
        "    \"\"\"\n",
        "    Explain a single review using DeepLift.\n",
        "    - instance: The text review.\n",
        "    - target_class: The predicted class (0 = negative, 1 = positive).\n",
        "    \"\"\"\n",
        "    instance_tfidf = vectorizer.transform([instance]).toarray()\n",
        "    instance_tensor = torch.tensor(instance_tfidf, dtype=torch.float32)\n",
        "    attributions = deep_lift.attribute(instance_tensor, target=target_class)\n",
        "    return attributions.detach().numpy().flatten()\n",
        "\n",
        "# Explain a sample review\n",
        "sample_review = X_test.iloc[0]\n",
        "sample_prediction = clf.predict(vectorizer.transform([sample_review]))[0]  # Get prediction\n",
        "explanation = explain_instance(sample_review, target_class=int(sample_prediction))  # Convert to int\n",
        "\n",
        "# Get words from vectorizer\n",
        "words = np.array(vectorizer.get_feature_names_out())\n",
        "\n",
        "# Normalize importance scores for color intensity\n",
        "normalized_importance = (explanation - np.min(explanation)) / (np.max(explanation) - np.min(explanation))\n",
        "\n",
        "# Highlight words in the review\n",
        "word_importance = dict(zip(words, normalized_importance))\n",
        "review_words = sample_review.split()\n",
        "highlighted_review = []\n",
        "for word in review_words:\n",
        "    clean_word = re.sub(r'[^a-zA-Z]', '', word).lower()\n",
        "    if clean_word in word_importance:\n",
        "        intensity = word_importance[clean_word]  # Normalized importance (0 to 1)\n",
        "        if explanation[words.tolist().index(clean_word)] > 0:\n",
        "            color = f'rgba(255, 0, 0, {intensity})'  # Red for positive words\n",
        "        else:\n",
        "            color = f'rgba(0, 0, 255, {intensity})'  # Blue for negative words\n",
        "        highlighted_review.append(f'<span style=\"background-color: {color};\"> {word} </span>')\n",
        "    else:\n",
        "        highlighted_review.append(word)\n",
        "\n",
        "highlighted_text = ' '.join(highlighted_review)\n",
        "display(HTML(f'<p style=\"font-size:16px;\">{highlighted_text}</p>'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "K9v6mdQY5v8g",
        "outputId": "f9f5879e-6b33-44bc-8bbb-f6c358c8396d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Accuracy: 0.8493\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85      4961\n",
            "           1       0.86      0.84      0.85      5039\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "Epoch 1/10, Loss: 0.6933\n",
            "Epoch 2/10, Loss: 0.6915\n",
            "Epoch 3/10, Loss: 0.6895\n",
            "Epoch 4/10, Loss: 0.6869\n",
            "Epoch 5/10, Loss: 0.6840\n",
            "Epoch 6/10, Loss: 0.6809\n",
            "Epoch 7/10, Loss: 0.6776\n",
            "Epoch 8/10, Loss: 0.6742\n",
            "Epoch 9/10, Loss: 0.6706\n",
            "Epoch 10/10, Loss: 0.6668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
            "               activations. The hooks and attributes will be removed\n",
            "            after the attribution is finished\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:16px;\">I <span style=\"background-color: rgba(255, 0, 0, 0.43901652097702026);\"> really </span> <span style=\"background-color: rgba(0, 0, 255, 0.23547492921352386);\"> liked </span> <span style=\"background-color: rgba(255, 0, 0, 0.4848284423351288);\"> this </span> Summerslam <span style=\"background-color: rgba(0, 0, 255, 0.24880288541316986);\"> due </span> <span style=\"background-color: rgba(255, 0, 0, 0.44742369651794434);\"> to </span> <span style=\"background-color: rgba(0, 0, 255, 0.36854952573776245);\"> the </span> <span style=\"background-color: rgba(255, 0, 0, 0.6187801361083984);\"> look </span> <span style=\"background-color: rgba(0, 0, 255, 0.31116628646850586);\"> of </span> <span style=\"background-color: rgba(0, 0, 255, 0.36854952573776245);\"> the </span> arena, <span style=\"background-color: rgba(0, 0, 255, 0.36854952573776245);\"> the </span> curtains <span style=\"background-color: rgba(0, 0, 255, 0.2638513445854187);\"> and </span> <span style=\"background-color: rgba(255, 0, 0, 0.5159635543823242);\"> just </span> <span style=\"background-color: rgba(0, 0, 255, 0.36854952573776245);\"> the </span> <span style=\"background-color: rgba(255, 0, 0, 0.6187801361083984);\"> look </span> <span style=\"background-color: rgba(0, 0, 255, 0.23026902973651886);\"> overall </span> <span style=\"background-color: rgba(255, 0, 0, 0.7484297752380371);\"> was </span> <span style=\"background-color: rgba(255, 0, 0, 0.7199481725692749);\"> interesting </span> <span style=\"background-color: rgba(255, 0, 0, 0.44742369651794434);\"> to </span> <span style=\"background-color: rgba(255, 0, 0, 0.40728554129600525);\"> me </span> <span style=\"background-color: rgba(255, 0, 0, 0.3984003961086273);\"> for </span> <span style=\"background-color: rgba(255, 0, 0, 0.4606040418148041);\"> some </span> <span style=\"background-color: rgba(255, 0, 0, 0.542640745639801);\"> reason. </span> <span style=\"background-color: rgba(0, 0, 255, 0.16097179055213928);\"> Anyways, </span> <span style=\"background-color: rgba(255, 0, 0, 0.4848284423351288);\"> this </span> <span style=\"background-color: rgba(255, 0, 0, 0.4941387176513672);\"> could </span> <span style=\"background-color: rgba(255, 0, 0, 0.5669386386871338);\"> have </span> <span style=\"background-color: rgba(255, 0, 0, 0.5015508532524109);\"> been </span> <span style=\"background-color: rgba(0, 0, 255, 0.37963005900382996);\"> one </span> <span style=\"background-color: rgba(0, 0, 255, 0.31116628646850586);\"> of </span> <span style=\"background-color: rgba(0, 0, 255, 0.36854952573776245);\"> the </span> <span style=\"background-color: rgba(0, 0, 255, 0.2588161528110504);\"> best </span> Summerslam's <span style=\"background-color: rgba(255, 0, 0, 0.47755083441734314);\"> ever </span> <span style=\"background-color: rgba(255, 0, 0, 0.47092175483703613);\"> if </span> <span style=\"background-color: rgba(0, 0, 255, 0.36854952573776245);\"> the </span> WWF didn't <span style=\"background-color: rgba(255, 0, 0, 0.5669386386871338);\"> have </span> Lex Luger <span style=\"background-color: rgba(0, 0, 255, 0.3512461185455322);\"> in </span> <span style=\"background-color: rgba(0, 0, 255, 0.36854952573776245);\"> the </span> <span style=\"background-color: rgba(255, 0, 0, 0.61644446849823);\"> main </span> <span style=\"background-color: rgba(255, 0, 0, 0.4406338930130005);\"> event </span> <span style=\"background-color: rgba(0, 0, 255, 0.0);\"> against </span> Yokozuna, <span style=\"background-color: rgba(0, 0, 255, 0.3131992816925049);\"> now </span> <span style=\"background-color: rgba(255, 0, 0, 0.3984003961086273);\"> for </span> <span style=\"background-color: rgba(0, 0, 255, 0.39358505606651306);\"> it's </span> <span style=\"background-color: rgba(255, 0, 0, 0.41707003116607666);\"> time </span> <span style=\"background-color: rgba(0, 0, 255, 0.30564388632774353);\"> it </span> <span style=\"background-color: rgba(255, 0, 0, 0.7484297752380371);\"> was </span> <span style=\"background-color: rgba(255, 0, 0, 0.5518085956573486);\"> ok </span> <span style=\"background-color: rgba(255, 0, 0, 0.44742369651794434);\"> to </span> <span style=\"background-color: rgba(255, 0, 0, 0.5669386386871338);\"> have </span> a <span style=\"background-color: rgba(255, 0, 0, 0.411368727684021);\"> huge </span> <span style=\"background-color: rgba(255, 0, 0, 0.6850889325141907);\"> fat </span> <span style=\"background-color: rgba(0, 0, 255, 0.13986165821552277);\"> man </span> <span style=\"background-color: rgba(255, 0, 0, 0.5329421162605286);\"> vs </span> a <span style=\"background-color: rgba(0, 0, 255, 0.19890595972537994);\"> strong </span> <span style=\"background-color: rgba(0, 0, 255, 0.13986165821552277);\"> man </span> <span style=\"background-color: rgba(255, 0, 0, 0.4236528277397156);\"> but </span> <span style=\"background-color: rgba(0, 0, 255, 0.39358505606651306);\"> I'm </span> <span style=\"background-color: rgba(0, 0, 255, 0.2525426745414734);\"> glad </span> <span style=\"background-color: rgba(0, 0, 255, 0.2898656725883484);\"> times </span> <span style=\"background-color: rgba(255, 0, 0, 0.5669386386871338);\"> have </span> <span style=\"background-color: rgba(0, 0, 255, 0.21480301022529602);\"> changed. </span> <span style=\"background-color: rgba(0, 0, 255, 0.30564388632774353);\"> It </span> <span style=\"background-color: rgba(255, 0, 0, 0.7484297752380371);\"> was </span> a <span style=\"background-color: rgba(255, 0, 0, 1.0);\"> terrible </span> <span style=\"background-color: rgba(255, 0, 0, 0.61644446849823);\"> main </span> <span style=\"background-color: rgba(255, 0, 0, 0.4406338930130005);\"> event </span> <span style=\"background-color: rgba(255, 0, 0, 0.5159635543823242);\"> just </span> <span style=\"background-color: rgba(255, 0, 0, 0.42879152297973633);\"> like </span> <span style=\"background-color: rgba(255, 0, 0, 0.40666186809539795);\"> every </span> <span style=\"background-color: rgba(255, 0, 0, 0.8723960518836975);\"> match </span> Luger <span style=\"background-color: rgba(0, 0, 255, 0.3521880507469177);\"> is </span> <span style=\"background-color: rgba(0, 0, 255, 0.3512461185455322);\"> in </span> <span style=\"background-color: rgba(0, 0, 255, 0.3521880507469177);\"> is </span> <span style=\"background-color: rgba(255, 0, 0, 1.0);\"> terrible. </span> <span style=\"background-color: rgba(0, 0, 255, 0.33489102125167847);\"> Other </span> <span style=\"background-color: rgba(0, 0, 255, 0.2501465082168579);\"> matches </span> <span style=\"background-color: rgba(255, 0, 0, 0.4601663649082184);\"> on </span> <span style=\"background-color: rgba(0, 0, 255, 0.36854952573776245);\"> the </span> <span style=\"background-color: rgba(255, 0, 0, 0.5170690417289734);\"> card </span> <span style=\"background-color: rgba(255, 0, 0, 0.4710727334022522);\"> were </span> Razor Ramon <span style=\"background-color: rgba(255, 0, 0, 0.5329421162605286);\"> vs </span> <span style=\"background-color: rgba(0, 0, 255, 0.14392776787281036);\"> Ted </span> Dibiase, Steiner <span style=\"background-color: rgba(0, 0, 255, 0.15811887383460999);\"> Brothers </span> <span style=\"background-color: rgba(255, 0, 0, 0.5329421162605286);\"> vs </span> Heavenly <span style=\"background-color: rgba(255, 0, 0, 0.6394484639167786);\"> Bodies, </span> Shawn Michaels <span style=\"background-color: rgba(255, 0, 0, 0.5329421162605286);\"> vs </span> Curt Hening, <span style=\"background-color: rgba(255, 0, 0, 0.4848284423351288);\"> this </span> <span style=\"background-color: rgba(255, 0, 0, 0.7484297752380371);\"> was </span> <span style=\"background-color: rgba(0, 0, 255, 0.36854952573776245);\"> the </span> <span style=\"background-color: rgba(255, 0, 0, 0.4406338930130005);\"> event </span> <span style=\"background-color: rgba(255, 0, 0, 0.4550822377204895);\"> where </span> Shawn <span style=\"background-color: rgba(0, 0, 255, 0.17887194454669952);\"> named </span> <span style=\"background-color: rgba(0, 0, 255, 0.3014315068721771);\"> his </span> <span style=\"background-color: rgba(0, 0, 255, 0.37730279564857483);\"> big </span> <span style=\"background-color: rgba(255, 0, 0, 0.6260131597518921);\"> monster </span> <span style=\"background-color: rgba(0, 0, 255, 0.31116628646850586);\"> of </span> a <span style=\"background-color: rgba(255, 0, 0, 0.5211548805236816);\"> body </span> <span style=\"background-color: rgba(0, 0, 255, 0.2287759929895401);\"> guard </span> Diesel, IRS <span style=\"background-color: rgba(255, 0, 0, 0.5329421162605286);\"> vs </span> 1-2-3 <span style=\"background-color: rgba(255, 0, 0, 0.524702250957489);\"> Kid, </span> Bret <span style=\"background-color: rgba(255, 0, 0, 0.5388185381889343);\"> Hart </span> <span style=\"background-color: rgba(0, 0, 255, 0.3539125621318817);\"> first </span> <span style=\"background-color: rgba(0, 0, 255, 0.03929072618484497);\"> takes </span> <span style=\"background-color: rgba(255, 0, 0, 0.4601663649082184);\"> on </span> Doink <span style=\"background-color: rgba(255, 0, 0, 0.5284043550491333);\"> then </span> <span style=\"background-color: rgba(0, 0, 255, 0.03929072618484497);\"> takes </span> <span style=\"background-color: rgba(255, 0, 0, 0.4601663649082184);\"> on </span> <span style=\"background-color: rgba(255, 0, 0, 0.416596382856369);\"> Jerry </span> Lawler <span style=\"background-color: rgba(0, 0, 255, 0.2638513445854187);\"> and </span> <span style=\"background-color: rgba(255, 0, 0, 0.5217309594154358);\"> stuff </span> <span style=\"background-color: rgba(0, 0, 255, 0.3705573081970215);\"> with </span> <span style=\"background-color: rgba(0, 0, 255, 0.36854952573776245);\"> the </span> Harts <span style=\"background-color: rgba(0, 0, 255, 0.2638513445854187);\"> and </span> Lawler <span style=\"background-color: rgba(255, 0, 0, 0.7484297752380371);\"> was </span> <span style=\"background-color: rgba(0, 0, 255, 0.2840951383113861);\"> always </span> <span style=\"background-color: rgba(0, 0, 255, 0.2927091717720032);\"> very </span> <span style=\"background-color: rgba(255, 0, 0, 0.7199481725692749);\"> interesting, </span> <span style=\"background-color: rgba(255, 0, 0, 0.5284043550491333);\"> then </span> Ludvig Borga <span style=\"background-color: rgba(255, 0, 0, 0.5629945993423462);\"> destroyed </span> <span style=\"background-color: rgba(0, 0, 255, 0.10741352289915085);\"> Marty </span> Jannetty, Undertaker <span style=\"background-color: rgba(0, 0, 255, 0.15796509385108948);\"> took </span> <span style=\"background-color: rgba(255, 0, 0, 0.4601663649082184);\"> on </span> <span style=\"background-color: rgba(255, 0, 0, 0.6168720126152039);\"> Giant </span> Gonzalez <span style=\"background-color: rgba(0, 0, 255, 0.3512461185455322);\"> in </span> <span style=\"background-color: rgba(255, 0, 0, 0.4141559302806854);\"> another </span> <span style=\"background-color: rgba(255, 0, 0, 1.0);\"> terrible </span> <span style=\"background-color: rgba(255, 0, 0, 0.8723960518836975);\"> match, </span> <span style=\"background-color: rgba(0, 0, 255, 0.36854952573776245);\"> The </span> <span style=\"background-color: rgba(255, 0, 0, 0.5586617588996887);\"> Smoking </span> Gunns <span style=\"background-color: rgba(0, 0, 255, 0.2638513445854187);\"> and </span> Tatanka <span style=\"background-color: rgba(0, 0, 255, 0.15796509385108948);\"> took </span> <span style=\"background-color: rgba(255, 0, 0, 0.4601663649082184);\"> on </span> Bam Bam Bigelow <span style=\"background-color: rgba(0, 0, 255, 0.2638513445854187);\"> and </span> <span style=\"background-color: rgba(0, 0, 255, 0.36854952573776245);\"> the </span> Headshrinkers, <span style=\"background-color: rgba(0, 0, 255, 0.2638513445854187);\"> and </span> Yokozuna defended <span style=\"background-color: rgba(0, 0, 255, 0.36854952573776245);\"> the </span> <span style=\"background-color: rgba(0, 0, 255, 0.24396926164627075);\"> world </span> <span style=\"background-color: rgba(255, 0, 0, 0.5214617848396301);\"> title </span> <span style=\"background-color: rgba(0, 0, 255, 0.0);\"> against </span> Lex Luger <span style=\"background-color: rgba(255, 0, 0, 0.4848284423351288);\"> this </span> <span style=\"background-color: rgba(255, 0, 0, 0.8723960518836975);\"> match </span> <span style=\"background-color: rgba(255, 0, 0, 0.7484297752380371);\"> was </span> <span style=\"background-color: rgba(255, 0, 0, 0.514051079750061);\"> boring </span> <span style=\"background-color: rgba(0, 0, 255, 0.2638513445854187);\"> and </span> <span style=\"background-color: rgba(0, 0, 255, 0.30564388632774353);\"> it </span> <span style=\"background-color: rgba(0, 0, 255, 0.3239004611968994);\"> has </span> a <span style=\"background-color: rgba(255, 0, 0, 1.0);\"> terrible </span> <span style=\"background-color: rgba(0, 0, 255, 0.37130245566368103);\"> ending. </span> <span style=\"background-color: rgba(255, 0, 0, 0.442060649394989);\"> However </span> <span style=\"background-color: rgba(0, 0, 255, 0.30564388632774353);\"> it </span> <span style=\"background-color: rgba(0, 0, 255, 0.18820157647132874);\"> deserves </span> 8/10</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics\n",
        "def fidelity_score(model, instance_tensor, attributions, target_class):\n",
        "    masked_tensor = instance_tensor.clone()\n",
        "    masked_tensor[:, np.abs(attributions) < np.percentile(np.abs(attributions), 50)] = 0\n",
        "    original_pred = model(instance_tensor).argmax(dim=1).item()\n",
        "    masked_pred = model(masked_tensor).argmax(dim=1).item()\n",
        "    return int(original_pred == masked_pred)\n",
        "\n",
        "def sparsity_score(attributions):\n",
        "    return 1.0 - (np.count_nonzero(attributions) / len(attributions))\n",
        "\n",
        "def stability_score(model, instance_tensor, attributions, target_class, noise_std=0.01):\n",
        "    noise = torch.randn_like(instance_tensor) * noise_std\n",
        "    perturbed_instance = instance_tensor + noise\n",
        "    original_attr = attributions\n",
        "    perturbed_attr = deep_lift.attribute(perturbed_instance, target=target_class).detach().numpy().flatten()\n",
        "    return 1 - (np.linalg.norm(original_attr - perturbed_attr) / np.linalg.norm(original_attr))\n",
        "\n",
        "def robustness_score(model, instance_tensor, attributions, target_class, noise_std=0.1):\n",
        "    noise = torch.randn_like(instance_tensor) * noise_std\n",
        "    perturbed_instance = instance_tensor + noise\n",
        "    original_pred = model(instance_tensor).argmax(dim=1).item()\n",
        "    perturbed_pred = model(perturbed_instance).argmax(dim=1).item()\n",
        "    return int(original_pred == perturbed_pred)\n",
        "\n",
        "# Explain and evaluate sample review\n",
        "sample_review = X_test.iloc[0]\n",
        "sample_prediction = clf.predict(vectorizer.transform([sample_review]))[0]\n",
        "instance_tensor = torch.tensor(vectorizer.transform([sample_review]).toarray(), dtype=torch.float32)\n",
        "explanation = explain_instance(sample_review, target_class=int(sample_prediction))\n",
        "\n",
        "fidelity = fidelity_score(model, instance_tensor, explanation, int(sample_prediction))\n",
        "sparsity = sparsity_score(explanation)\n",
        "stability = stability_score(model, instance_tensor, explanation, int(sample_prediction))\n",
        "robustness = robustness_score(model, instance_tensor, explanation, int(sample_prediction))\n",
        "\n",
        "print(f'Fidelity: {fidelity}')\n",
        "print(f'Sparsity: {sparsity:.4f}')\n",
        "print(f'Stability: {stability:.4f}')\n",
        "print(f'Robustness: {robustness:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXdSdAb-OOgj",
        "outputId": "514238de-9979-440b-a49d-62cdc938c980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fidelity: 1\n",
            "Sparsity: 0.9826\n",
            "Stability: 0.0940\n",
            "Robustness: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LIME**"
      ],
      "metadata": {
        "id": "uoXFoz2APK-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "id": "sVR7LshMPKl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import zipfile\n",
        "import re\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "# Mount Google Drive (if using Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "zip_path = '/content/drive/MyDrive/Reviews.zip'  # Path to the zip file\n",
        "extract_to = '/content/Reviews'  # Directory to extract the zip file\n",
        "data_path = os.path.join(extract_to, 'IMDB Dataset.csv')  # CSV file path\n",
        "\n",
        "# Extract the zip file\n",
        "def unzip_data(zip_path, extract_to):\n",
        "    if not os.path.exists(extract_to):\n",
        "        os.makedirs(extract_to)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Unzip the dataset\n",
        "unzip_data(zip_path, extract_to)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Convert sentiment labels to binary\n",
        "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text to numerical features\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Define a function for LIME to process text correctly\n",
        "def classifier_fn(texts):\n",
        "    \"\"\" Wrapper function to make LIME work with the classifier. \"\"\"\n",
        "    return clf.predict_proba(vectorizer.transform(texts))\n",
        "\n",
        "# Initialize LIME\n",
        "explainer = LimeTextExplainer(class_names=['negative', 'positive'])\n",
        "\n",
        "def explain_instance(instance):\n",
        "    \"\"\" Explain a single review using LIME. \"\"\"\n",
        "    exp = explainer.explain_instance(instance, classifier_fn, num_features=10)\n",
        "    return exp.as_list()\n",
        "\n",
        "# Test LIME explanation on a sample review\n",
        "sample_review = X_test.iloc[0]\n",
        "sample_prediction = clf.predict(vectorizer.transform([sample_review]))[0]  # Get prediction\n",
        "explanation = explain_instance(sample_review)\n",
        "\n",
        "# Normalize importance scores for better color scaling\n",
        "max_importance = max(abs(value) for _, value in explanation)\n",
        "\n",
        "# Highlight words in the review\n",
        "review_words = sample_review.split()\n",
        "highlighted_review = []\n",
        "for word in review_words:\n",
        "    clean_word = re.sub(r'[^a-zA-Z]', '', word).lower()\n",
        "    for key, value in explanation:\n",
        "        if key == clean_word:\n",
        "            intensity = abs(value) / max_importance  # Normalize intensity\n",
        "            color = f'rgba(255, 0, 0, {intensity})' if value > 0 else f'rgba(0, 0, 255, {intensity})'\n",
        "            highlighted_review.append(f'<span style=\"background-color: {color};\"> {word} </span>')\n",
        "            break\n",
        "    else:\n",
        "        highlighted_review.append(word)\n",
        "\n",
        "highlighted_text = ' '.join(highlighted_review)\n",
        "display(HTML(f'<p style=\"font-size:16px;\">{highlighted_text}</p>'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "zmBo0ZLRSHTq",
        "outputId": "3e8260dd-6ebb-48e0-f6c0-9d3e9760a274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Accuracy: 0.8493\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85      4961\n",
            "           1       0.86      0.84      0.85      5039\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:16px;\">I really liked <span style=\"background-color: rgba(0, 0, 255, 0.15411208424509237);\"> this </span> Summerslam due to the look of the arena, the curtains <span style=\"background-color: rgba(255, 0, 0, 0.18572092259331596);\"> and </span> just the look overall was interesting to me for some reason. Anyways, <span style=\"background-color: rgba(0, 0, 255, 0.15411208424509237);\"> this </span> could <span style=\"background-color: rgba(0, 0, 255, 0.17549780919013783);\"> have </span> been one of the <span style=\"background-color: rgba(255, 0, 0, 0.22184423750610552);\"> best </span> Summerslam's ever if the WWF didn't <span style=\"background-color: rgba(0, 0, 255, 0.17549780919013783);\"> have </span> Lex Luger in the main event against Yokozuna, now for it's time it was ok to <span style=\"background-color: rgba(0, 0, 255, 0.17549780919013783);\"> have </span> a huge fat man vs a <span style=\"background-color: rgba(255, 0, 0, 0.1609055544154762);\"> strong </span> man but I'm glad times <span style=\"background-color: rgba(0, 0, 255, 0.17549780919013783);\"> have </span> changed. It was a <span style=\"background-color: rgba(0, 0, 255, 1.0);\"> terrible </span> main event just like every match Luger is in is <span style=\"background-color: rgba(0, 0, 255, 1.0);\"> terrible. </span> Other matches on the card were Razor Ramon vs Ted Dibiase, Steiner Brothers vs Heavenly Bodies, Shawn Michaels vs Curt Hening, <span style=\"background-color: rgba(0, 0, 255, 0.15411208424509237);\"> this </span> was the event where Shawn named his big monster of a body guard Diesel, IRS vs 1-2-3 Kid, Bret Hart first takes on Doink then takes on Jerry Lawler <span style=\"background-color: rgba(255, 0, 0, 0.18572092259331596);\"> and </span> stuff with the Harts <span style=\"background-color: rgba(255, 0, 0, 0.18572092259331596);\"> and </span> Lawler was <span style=\"background-color: rgba(255, 0, 0, 0.12426489444519362);\"> always </span> <span style=\"background-color: rgba(255, 0, 0, 0.07265416419854767);\"> very </span> interesting, then Ludvig Borga destroyed Marty Jannetty, Undertaker took on Giant Gonzalez in another <span style=\"background-color: rgba(0, 0, 255, 1.0);\"> terrible </span> match, The Smoking Gunns <span style=\"background-color: rgba(255, 0, 0, 0.18572092259331596);\"> and </span> Tatanka took on Bam Bam Bigelow <span style=\"background-color: rgba(255, 0, 0, 0.18572092259331596);\"> and </span> the Headshrinkers, <span style=\"background-color: rgba(255, 0, 0, 0.18572092259331596);\"> and </span> Yokozuna defended the <span style=\"background-color: rgba(255, 0, 0, 0.07724043083951324);\"> world </span> title against Lex Luger <span style=\"background-color: rgba(0, 0, 255, 0.15411208424509237);\"> this </span> match was <span style=\"background-color: rgba(0, 0, 255, 0.8567697439113057);\"> boring </span> <span style=\"background-color: rgba(255, 0, 0, 0.18572092259331596);\"> and </span> it has a <span style=\"background-color: rgba(0, 0, 255, 1.0);\"> terrible </span> ending. However it deserves 8/10</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XAI Evaluation Metrics\n",
        "def fidelity_score(model, instance, explanation, target_class):\n",
        "    important_features = [word for word, _ in explanation[:5]]  # Top 5 important words\n",
        "    masked_instance = ' '.join([word if word.lower() not in important_features else '' for word in instance.split()])\n",
        "    original_pred = model.predict(vectorizer.transform([instance]))[0]\n",
        "    masked_pred = model.predict(vectorizer.transform([masked_instance]))[0]\n",
        "    return int(original_pred == masked_pred)\n",
        "\n",
        "def sparsity_score(explanation):\n",
        "    return 1.0 - (len(explanation) / 5000)  # Normalize by feature space size\n",
        "\n",
        "def stability_score(model, instance, explanation, target_class, noise_std=0.01):\n",
        "    perturbed_instance = instance + ' ' + ' '.join(np.random.choice(instance.split(), size=5))\n",
        "    original_exp = explain_instance(instance)\n",
        "    perturbed_exp = explain_instance(perturbed_instance)\n",
        "    return 1 - (np.linalg.norm(np.array([v for _, v in original_exp]) - np.array([v for _, v in perturbed_exp])) / np.linalg.norm(np.array([v for _, v in original_exp])))\n",
        "\n",
        "def robustness_score(model, instance, explanation, target_class, noise_std=0.1):\n",
        "    perturbed_instance = instance + ' ' + ' '.join(np.random.choice(instance.split(), size=5))\n",
        "    original_pred = model.predict(vectorizer.transform([instance]))[0]\n",
        "    perturbed_pred = model.predict(vectorizer.transform([perturbed_instance]))[0]\n",
        "    return int(original_pred == perturbed_pred)\n",
        "\n",
        "# Evaluate model on XAI metrics\n",
        "fidelity = fidelity_score(clf, sample_review, explanation, sample_prediction)\n",
        "sparsity = sparsity_score(explanation)\n",
        "stability = stability_score(clf, sample_review, explanation, sample_prediction)\n",
        "robustness = robustness_score(clf, sample_review, explanation, sample_prediction)\n",
        "\n",
        "print(f'Fidelity: {fidelity}')\n",
        "print(f'Sparsity: {sparsity:.4f}')\n",
        "print(f'Stability: {stability:.4f}')\n",
        "print(f'Robustness: {robustness:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD9y28HbT2kF",
        "outputId": "5a5cf92c-44eb-44a5-d40c-a586e0e901d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fidelity: 1\n",
            "Sparsity: 0.9980\n",
            "Stability: 0.5757\n",
            "Robustness: 1.0000\n"
          ]
        }
      ]
    }
  ]
}